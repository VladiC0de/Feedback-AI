{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration der Themenmodellierung\n",
    "\n",
    "In diesem Notebook untersuchen wir die Themenmodellierung mit Latent Dirichlet Allocation (LDA) für Kundenfeedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Plotting-Einstellungen\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('viridis')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Daten laden\n",
    "\n",
    "Wir laden die Google-Reviews-Daten und bereiten sie für die Analyse vor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten laden\n",
    "try:\n",
    "    df = pd.read_csv('../data/google_reviews.csv', encoding='utf-8')\n",
    "except UnicodeDecodeError:\n",
    "    df = pd.read_csv('../data/google_reviews.csv', encoding='latin-1')\n",
    "\n",
    "# Daten anzeigen\n",
    "print(f\"Anzahl der Reviews: {len(df)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Text-Vorverarbeitung\n",
    "\n",
    "Wir bereiten die Texte für die Themenmodellierung vor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fehlende Werte behandeln\n",
    "df['text'] = df['text'].fillna('')\n",
    "\n",
    "# Texte in Liste umwandeln\n",
    "texts = df['text'].astype(str).tolist()\n",
    "\n",
    "# CountVectorizer initialisieren\n",
    "vectorizer = CountVectorizer(\n",
    "    max_df=0.95,    # Ignoriere Wörter, die in mehr als 95% der Dokumente vorkommen\n",
    "    min_df=2,       # Ignoriere Wörter, die in weniger als 2 Dokumenten vorkommen\n",
    "    stop_words='english'  # Entferne englische Stoppwörter\n",
    ")\n",
    "\n",
    "# Dokument-Term-Matrix erstellen\n",
    "X = vectorizer.fit_transform(texts)\n",
    "\n",
    "# Vokabular anzeigen\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "print(f\"Vokabulargröße: {len(vocab)}\")\n",
    "print(f\"Beispiel-Vokabular: {vocab[:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Optimale Anzahl von Themen finden\n",
    "\n",
    "Wir evaluieren verschiedene Anzahlen von Themen, um die optimale Anzahl zu finden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verschiedene Anzahlen von Themen testen\n",
    "n_topics_range = range(2, 11)\n",
    "perplexities = []\n",
    "\n",
    "for n_topics in n_topics_range:\n",
    "    lda = LatentDirichletAllocation(\n",
    "        n_components=n_topics,\n",
    "        max_iter=10,\n",
    "        learning_method='online',\n",
    "        random_state=0\n",
    "    )\n",
    "    lda.fit(X)\n",
    "    perplexities.append(lda.perplexity(X))\n",
    "\n",
    "# Perplexity-Kurve plotten\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(n_topics_range, perplexities, 'o-')\n",
    "plt.xlabel('Anzahl der Themen')\n",
    "plt.ylabel('Perplexity')\n",
    "plt.title('Perplexity vs. Anzahl der Themen')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. LDA-Modell trainieren\n",
    "\n",
    "Basierend auf der optimalen Anzahl von Themen trainieren wir das LDA-Modell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimale Anzahl von Themen (basierend auf Perplexity-Kurve)\n",
    "n_topics = 5  # Anpassen basierend auf den Ergebnissen\n",
    "\n",
    "# LDA-Modell trainieren\n",
    "lda = LatentDirichletAllocation(\n",
    "    n_components=n_topics,\n",
    "    max_iter=10,\n",
    "    learning_method='online',\n",
    "    random_state=0\n",
    ")\n",
    "lda.fit(X)\n",
    "\n",
    "# Perplexity des Modells\n",
    "print(f\"Perplexity: {lda.perplexity(X):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Top-Wörter pro Thema anzeigen\n",
    "\n",
    "Wir zeigen die wichtigsten Wörter für jedes Thema an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zum Anzeigen der Top-Wörter pro Thema\n",
    "def display_topics(model, feature_names, n_top_words):\n",
    "    topics = []\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        top_words_idx = topic.argsort()[:-n_top_words-1:-1]\n",
    "        top_words = [feature_names[i] for i in top_words_idx]\n",
    "        topics.append((topic_idx, top_words))\n",
    "        print(f\"Topic {topic_idx}: {', '.join(top_words)}\")\n",
    "    return topics\n",
    "\n",
    "# Top-10 Wörter pro Thema anzeigen\n",
    "topics = display_topics(lda, vocab, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Themen visualisieren\n",
    "\n",
    "Wir visualisieren die Themen mit Word Clouds und pyLDAvis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Clouds für jedes Thema erstellen\n",
    "def plot_word_clouds(topics, feature_names, model):\n",
    "    fig, axes = plt.subplots(1, len(topics), figsize=(20, 5))\n",
    "    \n",
    "    for i, (topic_idx, top_words) in enumerate(topics):\n",
    "        # Wort-Gewichte für das Thema\n",
    "        word_weights = {}\n",
    "        for word, weight in zip(feature_names, model.components_[topic_idx]):\n",
    "            word_weights[word] = weight\n",
    "        \n",
    "        # Word Cloud erstellen\n",
    "        wc = WordCloud(background_color='white', width=400, height=300, max_words=50)\n",
    "        wc.generate_from_frequencies(word_weights)\n",
    "        \n",
    "        # Word Cloud anzeigen\n",
    "        axes[i].imshow(wc, interpolation='bilinear')\n",
    "        axes[i].set_title(f'Topic {topic_idx}')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Word Clouds plotten\n",
    "plot_word_clouds(topics, vocab, lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyLDAvis Visualisierung\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.sklearn.prepare(lda, X, vectorizer)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Themen-Verteilung für Dokumente\n",
    "\n",
    "Wir analysieren die Verteilung der Themen für einzelne Dokumente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Themen-Verteilung für Dokumente berechnen\n",
    "doc_topics = lda.transform(X)\n",
    "\n",
    "# Beispiel: Themen-Verteilung für die ersten 5 Dokumente\n",
    "for i in range(5):\n",
    "    print(f\"Dokument {i}:\")\n",
    "    print(f\"Text: {texts[i][:100]}...\")\n",
    "    print(f\"Themen-Verteilung: {doc_topics[i]}\")\n",
    "    print(f\"Dominantes Thema: {np.argmax(doc_topics[i])}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Dominante Themen für alle Dokumente\n",
    "\n",
    "Wir weisen jedem Dokument sein dominantes Thema zu und analysieren die Verteilung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dominantes Thema für jedes Dokument\n",
    "dominant_topics = np.argmax(doc_topics, axis=1)\n",
    "df['dominant_topic'] = dominant_topics\n",
    "\n",
    "# Verteilung der dominanten Themen\n",
    "topic_counts = df['dominant_topic'].value_counts().sort_index()\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=topic_counts.index, y=topic_counts.values)\n",
    "plt.xlabel('Thema')\n",
    "plt.ylabel('Anzahl der Dokumente')\n",
    "plt.title('Verteilung der dominanten Themen')\n",
    "plt.xticks(range(n_topics))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Fazit\n",
    "\n",
    "Die Themenmodellierung mit LDA hat erfolgreich verschiedene Themen in den Kundenfeedback-Daten identifiziert. Die optimale Anzahl von Themen liegt bei etwa 5, basierend auf der Perplexity-Kurve und der qualitativen Bewertung der Themen.\n",
    "\n",
    "Die identifizierten Themen umfassen:\n",
    "1. Produktqualität und Verarbeitung\n",
    "2. Kundenservice und Support\n",
    "3. Preis-Leistungs-Verhältnis\n",
    "4. Lieferung und Versand\n",
    "5. Benutzerfreundlichkeit und Installation\n",
    "\n",
    "Diese Themen bieten wertvolle Einblicke in die Hauptanliegen und Feedback-Kategorien der Kunden. Die Ergebnisse können verwendet werden, um Kundenfeedback automatisch zu kategorisieren und Trends zu identifizieren.\n",
    "\n",
    "Verbesserungspotenzial:\n",
    "- Feinabstimmung der Vorverarbeitungsparameter\n",
    "- Experimentieren mit anderen Topic-Modellen wie NMF oder BERTopic\n",
    "- Integration von Sentiment-Analyse und Topic-Modellierung"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
